{"keys":[{"path":["title"],"id":"title","weight":1,"src":"title","getFn":null},{"path":["body"],"id":"body","weight":1,"src":"body","getFn":null}],"records":[{"i":0,"$":{"0":{"v":"This page has not yet sprouted","n":0.408},"1":{"v":"[Dendron](https://dendron.so/) (the tool used to generate this site) lets authors selective publish content. You will see this page whenever you click on a link to an unpublished page\n\n![](https://foundation-prod-assetspublic53c57cce-8cpvgjldwysl.s3-us-west-2.amazonaws.com/assets/images/not-sprouted.png)","n":0.189}}},{"i":1,"$":{"0":{"v":"Zhirui Luo's Study Notes","n":0.5},"1":{"v":"\n# Hi, there!\n## This is a website for my study notes.\n\n## Contents\n- [[leetcode]]\n- [[database]]\n- [[designpattern]]","n":0.258}}},{"i":2,"$":{"0":{"v":"Leetcode","n":1},"1":{"v":"\n\n## Problem Sovling\nFour categories \n### API design\nLRU cache, insert delete get Random ALL O(1), design twitter\n### Abstraction\nskyline problem, int stream find median, cleaning robot\n\n### Programs\nthread pool, crawler, log merge, random generator\n\n### Dynamic programming\nsolid problem resolving\nbar raiser\n","n":0.167}}},{"i":3,"$":{"0":{"v":"Question List","n":0.707},"1":{"v":"\n- [Leetcode 面试高频题分类总结](https://zhuanlan.zhihu.com/p/349940945)\n\n- [Grokking the code interview patterns for coding questions](https://github.com/cl2333/Grokking-the-Coding-Interview-Patterns-for-Coding-Questions)\n- [Grokking to Leetcode](https://gist.github.com/tykurtz/3548a31f673588c05c89f9ca42067bc4)\n\n<!-- # Sort \n- Basic: Quick Sort, Merge Sort and their complexity.\n- Entry-level questions:\n    - Leetcode 148. Sort List\n    - Leetcode 56 -->\n\n","n":0.167}}},{"i":4,"$":{"0":{"v":"Prepare for LeetCode","n":0.577},"1":{"v":"\n## Important Algorithms\n### High Frequency\n- BFS\n- DFS\n- Binary Search\n- Two Pointers\n- Stack\n- Heap\n- Queue\n- Hashmap/Hashset\n- Prefix Sum\n- LinkedList\n- Binary Tree\n- Binary Search Tree\n- Quick Sort/ Merge Sort\n\n### Mid Frequency\n- DP\n- Sweep Line\n- Trie\n- Union Find\n- Monotone Stack/ Queue\n- TreeMap\n\n### Low Frequency\n- Dijkstra\n- Binary Indexed Tree\n- Segment Tree\n- Minimum Spanning Tree\n\n## Steps\n### Step 1\nBe familiar with high frequency algorithms and practice with easy question in Leetcode. \n\n### Step 2\nPractice based on categories for three repetations.\n\n### Step 3\nPrepare for most-frequency questions based on companys.\n\n### Step 4\nFollow up some mid-freq and low-freq questions.\n\n## Tips\n30% Easy, 60% Medium, 10% Hard. Know how to implement TreeMap in Python. \n\n### Some important questions\nInteger to English Words, Skyline, Integer to Roman.\n\n### Goal\nFinish questions within:\n- 10m for Medium\n- 15m for Hard\n","n":0.09}}},{"i":5,"$":{"0":{"v":"MergeSort VS QuickSort","n":0.577},"1":{"v":"\n[merge sort and quick sort](https://www.geeksforgeeks.org/quick-sort-vs-merge-sort/)\n\n## Quick Sort\nQuick sort is an internal algorithm which is based on divide and conquer strategy.\n- The array of elements is divided into parts repeatedly until it is not possible to divide it further.\n- It is also known as \"partition exchange sort\"\n- It uses a key element (pivot) for partitioning the elements\n- One left partition contains all those elements that are smaller than the pivot and one right partition contains all those elements which are greater than the key element. \n\n## Merge Sort\nMerge sort is an external algorithm and based on divide and conquer strategy.\n- The elements are split into two sub-arrays (n/2) again and again until only one element is left.\n- Merge sort uses additional storage for sorting the auxiliary array.\n- Merge sort uses three arrays where two are used for storing each half, and the third external one is used to store the final sorted list by merging other two and each array is then sorted recursively.\n- At last, the all sub arrays are merged to make it ‘n’ element size of the array.\n\n## Comparison\n| Basis for comparison | Quick Sort | Merge Sort |\n| --- | ---  | --- |\n| The partition of elements in the array | The splitting of a array of elements is in any ratio, not necessarily divided into half. |\tIn the merge sort, the array is parted into just 2 halves (i.e. n/2). |\n| Worst case complexity | O(n2) | O(nlogn) |\n| Works well on | It works well on smaller array | It operates fine on any size of array |\n| Speed of execution | It work faster than other sorting algorithms for small data set like Selection sort etc\t|  It has a consistent speed on any size of data | \n| Additional storage space requirement | Less(In-place) | More(not In-place) |  \n| Efficiency | Inefficient for larger arrays | More efficient |\n| Sorting method | Internal\t| External | \n| Stability | Not Stable | Stable |\n| Preferred for | for Arrays | for Linked Lists |\n| Locality of reference | good | poor |","n":0.054}}},{"i":6,"$":{"0":{"v":"Complexity","n":1},"1":{"v":"\nThe efficiency of an algorithm depends on two parameters:\n1. Time complexity: Time Complexity is defined as the number of times a particular instruction set is executed rather than the total time taken.\n\n2. Space complexity: Space Complexity is the total memory space required by the program for its execution. \n\nBoth are calculated as the function of input size(n).\n\n## Types Of Time Complexity:\n1. Best Time Complexity\n2. Average Time Complexity\n3. Worst Time Complexity\n\n\n## Sorting Algorithm\n| Algorithm ||Time Complexity  || Space Complexity|\n| --- | --- | --- | --- | --- |\n|  | Best | Average | Worst | Worst |\n| Selection Sort | $\\Omega(n^2)$ | $\\Theta(n^2)$| $O(n^2)$ | O(1) |\n\n\n## BFS and DFS\n| Parameters| BFS | DFS |\n| --- | --- | --- |\n|1. Stands for | BFS for Breadth First  Search | DFS stands for Depth First Search|\n| 2. Data Structure | BFS uses Queue | DFS uses stack |\n| 3. Definition | \tBFS is a traversal approach in which we first walk through all nodes on the same level before moving on to the next level.  | DFS is also a traversal approach in which the traverse begins at the root node and proceeds through the nodes as far as possible until we reach the node with no unvisited nearby nodes. |\n| 4. Technique | BFS can be used to find a single source shortest path in an unweighted graph because, in BFS, we reach a vertex with a minimum number of edges from a source vertex.  | In DFS, we might traverse through more edges to reach a destination vertex from a source. | \n| 5. Conceptual Difference | BFS builds the tree level by level. | DFS builds the tree sub-tree by sub-tree. |\n| 6. Approach used | It works on the concept of FIFO (First In First Out).  | It works on the concept of LIFO (Last In First Out). |\n| 7. Suitable for | BFS is more suitable for searching vertices closer to the given source. | DFS is more suitable when there are solutions away from source. |\n| 8. Time Complexity | $O(V+E)$ when Adjacency List is used and $O(V^2)$ when Adjacency Matrix is used, where V for vertices and E for edges. | $O(V+E)$ when Adjacency List is used and $O(V^2)$ when Adjacency Matrix is used. | \n| 9. Visiting of Siblings/ Children | Here, siblings are visited before the children. | Here, children are visited before the siblings. |\n| 10. Removal of Traversed Nodes | Nodes that are traversed several times are deleted from the queue. | The visited nodes are added to the stack and then removed when there are no more nodes to visit.|\n| 11. Backtracking | \tIn BFS there is no concept of backtracking.  | DFS algorithm is a recursive algorithm that uses the idea of backtracking |\n| 12. Applications | BFS is used in various applications such as bipartite graphs, shortest paths, etc. | DFS is used in various applications such as acyclic graphs and topological order etc.|\n| 13. Memory  |  BFS requires more memory.  | DFS requires less memory. |\n| 14. Optimality | BFS is optimal for finding the shortest path. | DFS is not optimal for finding the shortest path. |\n| 15. Space complexity |  \tIn BFS, the space complexity is more critical as compared to time complexity. |  DFS has lesser space complexity because at a time it needs to store only a single path from the root to the leaf node. | \n| 16. Speed | BFS is slow as compared to DFS. | DFS is fast as compared to BFS. |\n| 17. When to use? | When the target is close to the source, BFS performs better.  | When the target is far from the source, DFS is preferable. |","n":0.04}}},{"i":7,"$":{"0":{"v":"Design Patterns","n":0.707},"1":{"v":"\nGit repos:\n- [python-patterns](https://github.com/faif/python-patterns)\n- [repository pattern](https://gist.github.com/Greyvend/b56baa53b96e5bbfa7b650c3e6b69d40)\n- [Awesome Software and Architectural Design Patterns](https://github.com/DovAmir/awesome-design-patterns)\n- [System Design Primer](https://github.com/donnemartin/system-design-primer)","n":0.267}}},{"i":8,"$":{"0":{"v":"Database","n":1},"1":{"v":"\n## Database connection\n- Object Relational Mappers [[database.orm]]\n- Data Access Operation [[database.dao]]\n- Repository Pattern [[database.repositorypattern]]\n\n","n":0.267}}},{"i":9,"$":{"0":{"v":"Repository Pattern","n":0.707},"1":{"v":"\n## Repository Pattern\nAs per Eric Evans' book *Domain-Driven Design*, \"repository is a mechanism for encapsulating storage, retrieval, and search behavior, which emulates a collection of objects.\"\n\n## Comparing Repository Pattern with DAO\nTheir differences [link](https://www.baeldung.com/java-dao-vs-repository):\n- DAO is an abstraction of data persistence. However, a repository is an abstraction of a collection of objects\n- DAO is a lower-level conecpt, closer to the storage systems. However, repository is a higher-level concept, closer to the Domain objects.\n- DAO works as a data mapping/access layer, hiding ugly queries. However, a repository is a layer between domains and data access layers, hiding the complexity of collating data and preparing a domain object \n- DAO can't be implemeted using a repository. However, a reoisutirt can use a DAo for accessing underlying storage.","n":0.09}}},{"i":10,"$":{"0":{"v":"ORM vs DAO","n":0.577},"1":{"v":"\nORM and DAo are orthogonal concepts.","n":0.408}}},{"i":11,"$":{"0":{"v":"ORMs","n":1},"1":{"v":"\n## Object Relational Mappers (ORMs)\nAn object-relational mapper (ORM) is a code library that automates the transfer of data stored in relational database tables into objects that are more commonly used in application code.\n\n## ORM Tools For Python\n1. [SQLAlchemy](https://www.sqlalchemy.org/)\n2. [Peewee](http://docs.peewee-orm.com/en/latest/)\n3. [The Django ORM](https://docs.djangoproject.com/en/dev/topics/db/)\n4. [PonyORM](https://ponyorm.org/)\n5. [SQLObject](http://sqlobject.org/)\n6. [Tortoise ORM](https://tortoise-orm.readthedocs.io/en/latest/)\n\nORMs @ Full Stack Python [link](https://www.fullstackpython.com/object-relational-mappers-orms.html)\n\n## Example Implementation\nTo-do List App [[Rodolfo Campos, hackernoon.com, Oct. 15, 2021](https://hackernoon.com/building-a-to-do-list-app-with-python-data-access-layer-with-sqlalchemy)]\n\nThe actual implementation has the following components:\n1. Schema. Defines the database schema and provides connections wrapped in a Transaction Manager that keeps the database conversational state.\n2. BasRepo. It’s an abstract repository that implements the main 4 operations of a simple CRUD. Assuming that every table uses an auto-increment id field.\n3. UserRepo and tests. Extends BaseRepo for Users.\n4. TodRepo and tests. Extends BaseRepo for To-dos.\n\n## Schema\nAbout the implementation:\n\n- Uses an env variable for creating the engine\n- Defines the DB schema\n- Offers methods to create and drop the DB schema\n- Offers a Context Manager (TransactionManager) that wraps the connection and handles the DB conversational state. Easy to use with Python with statements.\n\n```python\nimport os\nfrom sqlalchemy import (\n    create_engine, \n    Boolean,\n    Column, \n    ForeignKey,\n    Integer, \n    MetaData, \n    String,\n    Table\n)\n\nclass Schema:\n    def __init__(self):\n        self.engine = create_engine(os.getenv(\"DB_URI\"), echo=True, future=True)\n        self.metadata = MetaData()\n        self.tables = self.__generate_tables()\n\n    def create_transaction(self):\n        return TransactionManager(self)        \n\n    def create_all_tables(self):\n        self.metadata.create_all(self.engine)\n\n    def drop_all_tables(self):\n        self.metadata.drop_all(self.engine)\n\n    def __generate_tables(self):\n        return {\n            'todo': Table('todo', self.metadata,\n                Column('id', Integer, primary_key=True , autoincrement=True),\n                Column('user_id', Integer, ForeignKey('user.id')),\n                Column('description', String(500)),\n                Column('active', Boolean)\n            ),\n            'user': Table('user', self.metadata,\n                Column('id', Integer, primary_key=True , autoincrement=True),\n                Column('email', String(50)),\n                Column('fullname', String(50))\n            ),\n        }\n\nclass TransactionManager:\n    def __init__(self, schema):\n        self.schema = schema\n        self.conn = self.schema.engine.connect()\n\n    def __enter__(self):\n        return self\n\n    def __exit__(self, type, value, traceback):\n        self.conn.commit()\n        self.conn.close()\n\n```\n\n## BaseRepo\nAbout the implementation:\n\n- Assumes that the table is defined in the schema and has an auto-increment id field.\n- Separates insert from update. You could implement just a save operation, similar to an upsert.\n- Returns cursors when finding all, not an array. Useful when handling several rows.\n\n```python\nfrom abc import ABC, abstractmethod\nfrom sqlalchemy import insert, select, update\nfrom sqlalchemy.exc import InvalidRequestError\n\nclass BaseRepo(ABC):\n    def __init__(self, tx):\n        self.conn = tx.conn\n        self.schema = tx.schema\n\n    def find_all(self):\n        stmt = select(self._get_table())\n        return self.conn.execute(stmt)\n\n    def find_by_id(self, id):\n        table = self._get_table()\n        stmt = select(table).where(table.c.id == id)\n        res = self.conn.execute(stmt)\n        if res:\n            return res.fetchone()\n\n    def insert(self, user):\n        table = self._get_table()\n        stmt = insert(table).values(user)\n        res = self.conn.execute(stmt)\n        return res.inserted_primary_key[0]\n\n    def update(self, user):\n        prev_user = self.find_by_id(user['id'])\n        if not prev_user:\n            raise InvalidRequestError('Invalid id')\n        stmt = update(self._get_table()).values(user)\n        self.conn.execute(stmt)\n\n    @abstractmethod\n    def _get_table(self):\n        pass\n```\n\n## TodoRepo\n\nAbout the implementation:\n\n- Extends BaseRepo.\n- Implements the only required method that returns the corresponding table from the Schema.\n- Any specific data access methods should be implemented here.\n\n```python\nfrom base_repo import BaseRepo\n\nclass TodoRepo(BaseRepo):\n    def _get_table(self):\n        return self.schema.tables['todo']\n```\n\n## TodoRepoTest\nAbout the implementation:\n\n- Uses in-memory sqlite DB, injected via env variables.\n- Groups in classes tests per each method in TodoRepo.\n- Creates a new schema per test.\n- Enables foreign constraints.\n\n```python\nimport pytest\nfrom sqlalchemy import event, insert, select\nfrom sqlalchemy.exc import IntegrityError, InvalidRequestError\n\nfrom schema import Schema\nfrom todo_repo import TodoRepo\n\n@pytest.fixture\ndef schema(monkeypatch):\n    monkeypatch.setenv(\"DB_URI\", \"sqlite://\")\n    schema = Schema()\n    _enable_foreign_constraints(schema)\n    schema.create_all_tables()\n    return schema\n\ndef _enable_foreign_constraints(schema):\n    def _fk_pragma_on_connect(dbapi_con, con_record):\n        dbapi_con.execute('pragma foreign_keys=ON')\n    event.listen(schema.engine, 'connect', _fk_pragma_on_connect)\n\nclass TestTodoRepo_find_all:\n    def test_when_multiple_todos(self, schema):\n        with schema.create_transaction() as tx:\n            insert_obj(tx, 'user', { 'id': 1, 'email': 'a@test.com', 'fullname': 'fullname a' })\n            insert_obj(tx, 'todo', { 'id': 1, 'user_id': 1, 'description': 'description a', 'active': True })\n            insert_obj(tx, 'todo', { 'id': 2, 'user_id': 1, 'description': 'description b', 'active': False })\n            todos = TodoRepo(tx).find_all().fetchall()\n            assert len(todos) == 2\n            assert todos[0]['id'] == 1\n            assert todos[0]['user_id'] == 1\n            assert todos[0]['description'] == 'description a'\n            assert todos[0]['active'] == True\n            assert todos[1]['id'] == 2\n            assert todos[1]['user_id'] == 1\n            assert todos[1]['description'] == 'description b'\n            assert todos[1]['active'] == False\n\n    def test_when_empty(self, schema):\n        with schema.create_transaction() as tx:\n            todos = TodoRepo(tx).find_all().fetchall()\n            assert len(todos) == 0\n\nclass TestTodoRepo_find_by_id:\n    def test_when_todo_exists(self, schema):\n        with schema.create_transaction() as tx:\n            insert_obj(tx, 'user', { 'id': 1, 'email': 'a@test.com', 'fullname': 'fullname a' })\n            insert_obj(tx, 'todo', { 'id': 1, 'user_id': 1, 'description': 'description a', 'active': True })\n            insert_obj(tx, 'todo', { 'id': 2, 'user_id': 1, 'description': 'description b', 'active': False })\n            todo = TodoRepo(tx).find_by_id(1)\n            assert todo['id'] == 1\n            assert todo['user_id'] == 1\n            assert todo['description'] == 'description a'\n            assert todo['active'] == True\n\n    def test_when_todo_does_not_exists(self, schema):\n        with schema.create_transaction() as tx:\n            todo = TodoRepo(tx).find_by_id(1)\n            assert todo is None\n\nclass TestTodoRepo_insert:\n    def test_when_auto_increment_id(self, schema):\n        with schema.create_transaction() as tx:\n            insert_obj(tx, 'user', { 'id': 1, 'email': 'a@test.com', 'fullname': 'fullname a' })\n            id = TodoRepo(tx).insert({ 'user_id': 1, 'description': 'description a', 'active': True })\n            table = tx.schema.tables['todo']\n            todos = tx.conn.execute(select(table)).fetchall()\n            assert len(todos) == 1\n            assert todos[0]['id'] == id\n            assert todos[0]['user_id'] == 1\n            assert todos[0]['description'] == 'description a'\n            assert todos[0]['active'] == True\n\n    def test_when_set_id(self, schema):\n        with schema.create_transaction() as tx:\n            insert_obj(tx, 'user', { 'id': 1, 'email': 'a@test.com', 'fullname': 'fullname a' })\n            TodoRepo(tx).insert({ 'id': 99, 'user_id': 1, 'description': 'description a', 'active': True })\n            table = tx.schema.tables['todo']\n            todos = tx.conn.execute(select(table)).fetchall()\n            assert len(todos) == 1\n            assert todos[0]['id'] == 99\n            assert todos[0]['user_id'] == 1\n            assert todos[0]['description'] == 'description a'\n            assert todos[0]['active'] == True\n\n    def test_when_invalid_id(self, schema):\n        with schema.create_transaction() as tx, pytest.raises(IntegrityError):\n            insert_obj(tx, 'user', { 'id': 1, 'email': 'a@test.com', 'fullname': 'fullname a' })\n            TodoRepo(tx).insert({ 'id': 'invalid', 'user_id': 1, 'description': 'description a', 'active': True })\n\n    def test_when_invalid_user_id(self, schema):\n        with schema.create_transaction() as tx, pytest.raises(IntegrityError):\n            TodoRepo(tx).insert({ 'id': 1, 'user_id': 1, 'description': 'description a', 'active': True })\n\n    def test_when_duplicated_id(self, schema):\n        with schema.create_transaction() as tx, pytest.raises(IntegrityError):\n            repo = TodoRepo(tx)\n            repo.insert({ 'id': 1, 'user_id': 1, 'description': 'description a', 'active': True })\n            repo.insert({ 'id': 1, 'user_id': 1, 'description': 'description a', 'active': True })\n\nclass TestTodoRepo_update:\n    def test_when_todo_exists(self, schema):\n        with schema.create_transaction() as tx:\n            insert_obj(tx, 'user', { 'id': 1, 'email': 'a@test.com', 'fullname': 'fullname a' })\n            insert_obj(tx, 'user', { 'id': 2, 'email': 'b@test.com', 'fullname': 'fullname b' })\n            insert_obj(tx, 'todo', { 'id': 1, 'user_id': 1, 'description': 'description a', 'active': True })\n            TodoRepo(tx).update({ 'id': 1, 'user_id': 2, 'description': 'description b', 'active': False })\n            table = tx.schema.tables['todo']\n            todos = tx.conn.execute(select(table)).fetchall()\n            assert len(todos) == 1\n            assert todos[0]['id'] == 1\n            assert todos[0]['user_id'] == 2\n            assert todos[0]['description'] == 'description b'\n            assert todos[0]['active'] == False\n\n    def test_when_todo_does_not_exists(self, schema):\n        with schema.create_transaction() as tx, pytest.raises(InvalidRequestError):\n            TodoRepo(tx).update({ 'id': 1, 'user_id': 1, 'description': 'description b', 'active': False })\n\ndef insert_obj(tx, table_name, obj):\n    table = tx.schema.tables[table_name]\n    stmt = insert(table).values(obj)\n    tx.conn.execute(stmt)\n```","n":0.032}}},{"i":12,"$":{"0":{"v":"Data Access Object (DAO) Pattern","n":0.447},"1":{"v":"\n## A Design Pattern\nDAO is a design pattern to minimize coupling between your application and your backend where ORM deals with how to map objects into an object-relational database. This reduce the coupling between the database and your application.\n\nPotential disadvantages of using DAO include leaky abstraction, code duplication, and abstraction inversion.\n\n## Example\n[dao-vs-ormhibernate-pattern](https://stackoverflow.com/questions/4037251/dao-vs-ormhibernate-pattern/4037454#4037454)\n\n```java\npublic class Application\n{\n    private UserDao userDao;\n\n    public Application(UserDao dao)\n    {\n        // Get the actual implementation\n        // e.g. through dependency injection\n        this.userDao = dao;\n    }\n\n    public void login()\n    {\n        // No matter from where\n        User = userDao.findByUsername(\"Dummy\");\n    }\n}\n\n\npublic interface UserDao\n{\n    User findByUsername(String name);\n}\n\npublic class HibernateUserDao implements UserDao\n{\n    public User findByUsername(String name)\n    {\n        // Do some Hibernate specific stuff\n        this.session.createQuery...\n    }\n}\n\npublic class SqlUserDao implements UserDao\n{\n    public User findByUsername(String name)\n    {\n        String query = \"SELECT * FROM users WHERE name = '\" + name + \"'\";\n        // Execute SQL query and do mapping to the object\n    }\n}\n\npublic class LdapUserDao implements UserDao\n{\n    public User findByUsername(String name)\n    {\n        // Get this from LDAP directory\n    }\n}\n\npublic class NoSqlUserDao implements UserDao\n{\n    public User findByUsername(String name)\n    {\n        // Do something with e.g. couchdb\n        ViewResults resultAdHoc = db.adhoc(\"function (doc) { if (doc.name=='\" + name + \"') { return doc; }}\");\n        // Map the result document to user\n    }\n}\n```","n":0.071}}}]}
